{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VBOW.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vQ_FzImWRUUc",
        "mUkLd_R6RXkN",
        "My1gUMd5RchA",
        "nCR4aTcpRguG",
        "IZg9N0uVRoAK",
        "mQyV1j4ySw7S",
        "nqqjTmMBS9ue",
        "IRxMHNtvTBp8",
        "dboeCtJgTlYr",
        "4x_0Drv7T89L"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hexterisk/CT-GAN/blob/master/VBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ_FzImWRUUc",
        "colab_type": "text"
      },
      "source": [
        "# Base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUkLd_R6RXkN",
        "colab_type": "text"
      },
      "source": [
        "## Mounting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37E2giJ0Ra8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My1gUMd5RchA",
        "colab_type": "text"
      },
      "source": [
        "## Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXfHF5Y7Re0Y",
        "colab_type": "code",
        "outputId": "04e08fa3-36de-4bbb-f4b1-3976958100ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "!pip install plotly scikit-image dicom pydicom opencv-python==3.4.2.16 numpy Keras tensorflow opencv-contrib-python==3.4.2.16"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (4.3.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (4.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (0.2.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (2.8)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image) (0.46)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.5.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.15.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCR4aTcpRguG",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR_U9JENRkHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pydicom\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "import scipy.ndimage\n",
        "from skimage import morphology\n",
        "from skimage import measure\n",
        "from skimage.transform import resize\n",
        "from sklearn.cluster import KMeans\n",
        "from plotly import __version__\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "from plotly.tools import FigureFactory as FF\n",
        "from plotly.figure_factory import create_trisurf\n",
        "from plotly.graph_objs import *\n",
        "import dicom\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from scipy.spatial import distance\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZg9N0uVRoAK",
        "colab_type": "text"
      },
      "source": [
        "# Listing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEZMMuo4Rv2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tampered_root_path = \"/content/drive/My Drive/ICSML-2019/Tampered Scans\"\n",
        "original_root_path = \"/content/drive/My Drive/ICSML-2019/Origional Scans\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L676LHktR4Ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exp1labels = np.genfromtxt('/content/drive/My Drive/ICSML-2019/Tampered Scans/labels_exp1.csv', delimiter=',')\n",
        "exp2labels = np.genfromtxt('/content/drive/My Drive/ICSML-2019/Tampered Scans/labels_exp2.csv', delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJKPz6dBSstC",
        "colab_type": "text"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQyV1j4ySw7S",
        "colab_type": "text"
      },
      "source": [
        "## Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_PGig7BSLWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loads images from tampered directory. Takes in parameters of root path and the label file. Returns dictionary of tampered scans in value and 'tampered' in key.\n",
        "\n",
        "def load_images_from_folder_tampered(root, labels):\n",
        "  print(\"Root folder: \", root)\n",
        "  category = []\n",
        "  images = {}\n",
        "  for i in range(1, len(labels)):\n",
        "    #print(str(int(labels[i][1])), \" : \", str(int(labels[i][2])))\n",
        "    if((int(labels[i][3]) != 0) and (int(labels[i][4])) != 0):\n",
        "      path = root + '/Experiment 1 - Blind/' + str(int(labels[i][1])) + '/' + str(int(labels[i][2])) + \".dcm\"\n",
        "      if(os.path.isfile(path)==True):\n",
        "        img = dicom.read_file(path)\n",
        "        category.append(get_lbp_image(img.pixel_array))\n",
        "      else:\n",
        "        path = root + '/Experiment 2 - Open/' + str(int(labels[i][1])) + '/' + str(int(labels[i][2])) + \".dcm\"\n",
        "        if(os.path.isfile(path)==True):\n",
        "          img = dicom.read_file(path)\n",
        "          category.append(get_lbp_image(img.pixel_array))\n",
        "        else:\n",
        "          print(\"FILE DOES NOT EXIST!\")\n",
        "    else:\n",
        "      continue\n",
        "  images['tampered'] = category\n",
        "  return images  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcMeuHHLSXEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loads images from original directory. Takes in parameters of root path and the label file. Returns dictionary of original scans in value and 'original' in key.\n",
        "\n",
        "def load_images_from_folder_original(root, labels):\n",
        "  print(\"Root folder: \", root)\n",
        "  category = []\n",
        "  images = {}\n",
        "  for i in range(1, len(labels)):\n",
        "    if((int(labels[i][3]) != 0) and (int(labels[i][4])) != 0):\n",
        "      found = False\n",
        "      #print(str(int(labels[i][1])), \" : \", str(int(labels[i][2])))\n",
        "      root_path = root + '/set1'\n",
        "      for original_image_path in os.listdir(root_path):\n",
        "        parsed_original_image_path = original_image_path.split(\".\")[-1][0:4]\n",
        "        if(str(int(labels[i][1])) == parsed_original_image_path):\n",
        "          path = root_path + '/' + original_image_path + '/' + str(int(labels[i][2])) + \".dcm\"\n",
        "          if(os.path.isfile(path)==True):\n",
        "            found = True\n",
        "            img = dicom.read_file(path)\n",
        "            category.append(get_lbp_image(img.pixel_array))\n",
        "      if(found == False):\n",
        "        root_path = root + '/set2'\n",
        "        for original_image_path in os.listdir(root_path):\n",
        "          parsed_original_image_path = original_image_path.split(\".\")[-1][0:4]\n",
        "          if(str(int(labels[i][1])) == parsed_original_image_path):\n",
        "            path = root_path + '/' + original_image_path + '/' + str(int(labels[i][2])) + \".dcm\"\n",
        "            if(os.path.isfile(path)==True):\n",
        "              found = True\n",
        "              img = dicom.read_file(path)\n",
        "              category.append(get_lbp_image(img.pixel_array))\n",
        "              #np.array(img.pixel_array, dtype=np.uint8)\n",
        "            else:\n",
        "              print(\"FILE DOES NOT EXIST!\")\n",
        "    else:\n",
        "      continue\n",
        "  images['original'] = category\n",
        "  return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa4zLqSySoQE",
        "colab_type": "text"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqqjTmMBS9ue",
        "colab_type": "text"
      },
      "source": [
        "### LBP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91_fPfWQS6xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pixel(img, center, x, y):\n",
        "    new_value = 0\n",
        "    try:\n",
        "        if img[x][y] >= center:\n",
        "            new_value = 1\n",
        "    except:\n",
        "        pass\n",
        "    return new_value\n",
        "\n",
        "def lbp_calculated_pixel(img, x, y):\n",
        "    '''\n",
        "\n",
        "     64 | 128 |   1\n",
        "    ----------------\n",
        "     32 |   0 |   2\n",
        "    ----------------\n",
        "     16 |   8 |   4    \n",
        "\n",
        "    '''    \n",
        "    center = img[x][y]\n",
        "    val_ar = []\n",
        "    val_ar.append(get_pixel(img, center, x-1, y+1))     # top_right\n",
        "    val_ar.append(get_pixel(img, center, x, y+1))       # right\n",
        "    val_ar.append(get_pixel(img, center, x+1, y+1))     # bottom_right\n",
        "    val_ar.append(get_pixel(img, center, x+1, y))       # bottom\n",
        "    val_ar.append(get_pixel(img, center, x+1, y-1))     # bottom_left\n",
        "    val_ar.append(get_pixel(img, center, x, y-1))       # left\n",
        "    val_ar.append(get_pixel(img, center, x-1, y-1))     # top_left\n",
        "    val_ar.append(get_pixel(img, center, x-1, y))       # top\n",
        "    \n",
        "    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
        "    val = 0\n",
        "    for i in range(len(val_ar)):\n",
        "        val += val_ar[i] * power_val[i]\n",
        "    return val    \n",
        "\n",
        "def show_output(output_list):\n",
        "    output_list_len = len(output_list)\n",
        "    figure = plt.figure(figsize=(15, 15))\n",
        "    for i in range(output_list_len):\n",
        "        current_dict = output_list[i]\n",
        "        current_img = current_dict[\"img\"]\n",
        "        current_xlabel = current_dict[\"xlabel\"]\n",
        "        current_ylabel = current_dict[\"ylabel\"]\n",
        "        current_xtick = current_dict[\"xtick\"]\n",
        "        current_ytick = current_dict[\"ytick\"]\n",
        "        current_title = current_dict[\"title\"]\n",
        "        current_type = current_dict[\"type\"]\n",
        "        current_plot = figure.add_subplot(1, output_list_len, i+1)\n",
        "        if current_type == \"gray\":\n",
        "            current_plot.imshow(current_img, cmap = plt.get_cmap('gray'))\n",
        "            current_plot.set_title(current_title)\n",
        "            current_plot.set_xticks(current_xtick)\n",
        "            current_plot.set_yticks(current_ytick)\n",
        "            current_plot.set_xlabel(current_xlabel)\n",
        "            current_plot.set_ylabel(current_ylabel)\n",
        "        elif current_type == \"histogram\":\n",
        "            current_plot.plot(current_img, color = \"black\")\n",
        "            current_plot.set_xlim([0,260])\n",
        "            current_plot.set_title(current_title)\n",
        "            current_plot.set_xlabel(current_xlabel)\n",
        "            current_plot.set_ylabel(current_ylabel)            \n",
        "            ytick_list = [int(i) for i in current_plot.get_yticks()]\n",
        "            current_plot.set_yticklabels(ytick_list,rotation = 90)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def get_dicom_grayscale_cv2(data):\n",
        "    pil_image = Image.fromarray(data.astype('uint8'), 'P')\n",
        "    rgbimg = Image.new(\"RGB\", pil_image.size)\n",
        "    rgbimg.paste(pil_image)\n",
        "    img = cv2.cvtColor(np.array(rgbimg).astype('uint8'), cv2.COLOR_BGR2GRAY)\n",
        "    return img\n",
        "  \n",
        "def get_lbp_image(img_dicom):\n",
        "    img_dicom_gray = get_dicom_grayscale_cv2(img_dicom)\n",
        "    height, width = img_dicom_gray.shape\n",
        "    \n",
        "    img_lbp = np.zeros((height, width, 3), np.uint8)\n",
        "    for i in range(0, height):\n",
        "        for j in range(0, width):\n",
        "            img_lbp[i, j] = lbp_calculated_pixel(img_dicom_gray, i, j)\n",
        "\n",
        "    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n",
        "    output_list = []\n",
        "    output_list.append({\n",
        "        \"img\": img_dicom_gray,\n",
        "        \"xlabel\": \"\",\n",
        "        \"ylabel\": \"\",\n",
        "        \"xtick\": [],\n",
        "        \"ytick\": [],\n",
        "        \"title\": \"Gray Image\",\n",
        "        \"type\": \"gray\"        \n",
        "    })\n",
        "    output_list.append({\n",
        "        \"img\": img_lbp,\n",
        "        \"xlabel\": \"\",\n",
        "        \"ylabel\": \"\",\n",
        "        \"xtick\": [],\n",
        "        \"ytick\": [],\n",
        "        \"title\": \"LBP Image\",\n",
        "        \"type\": \"gray\"\n",
        "    })    \n",
        "    # output_list.append({\n",
        "    #     \"img\": hist_lbp,\n",
        "    #     \"xlabel\": \"Bins\",\n",
        "    #     \"ylabel\": \"Number of pixels\",\n",
        "    #     \"xtick\": None,\n",
        "    #     \"ytick\": None,\n",
        "    #     \"title\": \"Histogram(LBP)\",\n",
        "    #     \"type\": \"histogram\"\n",
        "    # })\n",
        "\n",
        "    return img_lbp#, output_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRxMHNtvTBp8",
        "colab_type": "text"
      },
      "source": [
        "### SIFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zPA41nkS4fL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates descriptors using sift \n",
        "# Takes one parameter that is images dictionary\n",
        "# Return an array whose first index holds the decriptor_list without an order\n",
        "# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n",
        "def sift_features(images):\n",
        "    sift_vectors = {}\n",
        "    descriptor_list = []\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    for key,value in images.items():\n",
        "        #plt.imshow(value)\n",
        "        features = []\n",
        "        for img in value:\n",
        "            kp, des = sift.detectAndCompute(img,None)\n",
        "           \n",
        "            \n",
        "            descriptor_list.extend(des)\n",
        "            features.append(des)\n",
        "        sift_vectors[key] = features\n",
        "    return [descriptor_list, sift_vectors]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gSLPbKEaG-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_sift_features(gray_img):\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    # kp is the keypoints\n",
        "    #\n",
        "    # desc is the SIFT descriptors, they're 128-dimensional vectors\n",
        "    # that we can use for our final features\n",
        "    kp, desc = sift.detectAndCompute(gray_img, None)\n",
        "    return kp, desc\n",
        "\n",
        "def show_sift_features(gray_img, color_img, kp):\n",
        "    return plt.imshow(cv2.drawKeypoints(gray_img, kp, color_img.copy()))\n",
        "\n",
        "def draw(img_lbp, img_tlbp):\n",
        "    okp, odesc = gen_sift_features(img_lbp)\n",
        "    o_tkp, o_tdesc = gen_sift_features(img_tlbp)\n",
        "\n",
        "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "    matches = bf.match(odesc, o_tdesc)\n",
        "    # Sort the matches in the order of their distance.\n",
        "    matches = sorted(matches, key = lambda x:x.distance)\n",
        "    # draw the top N matches\n",
        "    N_MATCHES = 100\n",
        "\n",
        "    match_img = cv2.drawMatches(\n",
        "        img_lbp, okp,\n",
        "        img_tlbp, o_tkp,\n",
        "        matches[:N_MATCHES], img_tlbp.copy(), flags=0)\n",
        "    \n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.imshow(match_img);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYGcbN_XTYny",
        "colab_type": "text"
      },
      "source": [
        "### K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSec73TssXnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kplot(centroids, reduced_data):\n",
        "  # Step size of the mesh. Decrease to increase the quality of the VQ.\n",
        "  h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "\n",
        "  # Plot the decision boundary. For that, we will assign a color to each\n",
        "  x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
        "  y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "  plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
        "  # Plot the centroids as a blue X\n",
        "  plt.scatter(centroids[:, 0], centroids[:, 1],\n",
        "              marker='x', s=169, linewidths=3,\n",
        "              color='b', zorder=10)\n",
        "  plt.title('K-means clustering (PCA-reduced data)\\n'\n",
        "            'Centroids are marked with blue cross')\n",
        "  plt.xlim(x_min, x_max)\n",
        "  plt.ylim(y_min, y_max)\n",
        "  plt.xticks(())\n",
        "  plt.yticks(())\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABY9urYfTWAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A k-means clustering algorithm who takes 2 parameter which is number \n",
        "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
        "# Returns an array that holds central points.\n",
        "def kmeans(k, descriptor_list):\n",
        "    kmeans = KMeans(n_clusters = k, n_init=10)\n",
        "    kmeans.fit(descriptor_list)\n",
        "    visual_words = kmeans.cluster_centers_ \n",
        "    kplot(visual_words, np.array(descriptor_list))\n",
        "    return visual_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dboeCtJgTlYr",
        "colab_type": "text"
      },
      "source": [
        "### Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RpxmeQ1Tq2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_index(image, center):\n",
        "    count = 0\n",
        "    ind = 0\n",
        "    for i in range(len(center)):\n",
        "        if(i == 0):\n",
        "           count = distance.euclidean(image, center[i]) \n",
        "           #count = L1_dist(image, center[i])\n",
        "        else:\n",
        "            dist = distance.euclidean(image, center[i]) \n",
        "            #dist = L1_dist(image, center[i])\n",
        "            if(dist < count):\n",
        "                ind = i\n",
        "                count = dist\n",
        "    return ind\n",
        "  \n",
        "# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n",
        "# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n",
        "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
        "def image_class(all_bovw, centers):\n",
        "    dict_feature = {}\n",
        "    for key,value in all_bovw.items():\n",
        "        category = []\n",
        "        for img in value:\n",
        "            histogram = np.zeros(len(centers))\n",
        "            for each_feature in img:\n",
        "                ind = find_index(each_feature, centers)\n",
        "                histogram[ind] += 1\n",
        "            category.append(histogram)\n",
        "        dict_feature[key] = category\n",
        "    return dict_feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA2l5SnoT0rV",
        "colab_type": "text"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I8Lfca4Tz23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1-NN algorithm. We use this for predict the class of test images.\n",
        "# Takes 2 parameters. images is the feature vectors of train images and tests is the feature vectors of test images\n",
        "# Returns an array that holds number of test images, number of correctly predicted images and records of class based images respectively\n",
        "def knn(images, tests):\n",
        "    num_test = 0\n",
        "    correct_predict = 0\n",
        "    class_based = {}\n",
        "    \n",
        "    for test_key, test_val in tests.items():\n",
        "        class_based[test_key] = [0, 0] # [correct, all]\n",
        "        for tst in test_val:\n",
        "            predict_start = 0\n",
        "            #print(test_key)\n",
        "            minimum = 0\n",
        "            key = \"a\" #predicted\n",
        "            for train_key, train_val in images.items():\n",
        "                for train in train_val:\n",
        "                    if(predict_start == 0):\n",
        "                        minimum = distance.euclidean(tst, train)\n",
        "                        #minimum = L1_dist(tst,train)\n",
        "                        key = train_key\n",
        "                        predict_start += 1\n",
        "                    else:\n",
        "                        dist = distance.euclidean(tst, train)\n",
        "                        #dist = L1_dist(tst,train)\n",
        "                        if(dist < minimum):\n",
        "                            minimum = dist\n",
        "                            key = train_key\n",
        "            \n",
        "            if(test_key == key):\n",
        "                correct_predict += 1\n",
        "                class_based[test_key][0] += 1\n",
        "            num_test += 1\n",
        "            class_based[test_key][1] += 1\n",
        "            #print(minimum)\n",
        "    return [num_test, correct_predict, class_based]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x_0Drv7T89L",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WiFJD4_T-CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculates the average accuracy and class based accuracies.  \n",
        "def accuracy(results):\n",
        "    avg_accuracy = (results[1] / results[0]) * 100\n",
        "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
        "    print(\"\\nClass based accuracies: \\n\")\n",
        "    for key,value in results[2].items():\n",
        "        acc = (value[0] / value[1]) * 100\n",
        "        print(key + \" : %\" + str(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3y7KTQBUBzY",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeAtXWOqTImw",
        "colab_type": "code",
        "outputId": "d4ecac48-9fca-4276-ae82-5822d23b618d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "images_train = {}\n",
        "images_tamp = load_images_from_folder_tampered(tampered_root_path, exp1labels)\n",
        "images_orig = load_images_from_folder_original(original_root_path, exp1labels)\n",
        "\n",
        "images_train.update(images_orig)\n",
        "images_train.update(images_tamp)\n",
        "\n",
        "print(len(images_train['tampered']))\n",
        "print(len(images_train['original']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root folder:  /content/drive/My Drive/ICSML-2019/Tampered Scans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIbR7ac7TPD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_test = {}\n",
        "\n",
        "images_tamp_test = load_images_from_folder_tampered(tampered_root_path, exp2labels)\n",
        "images_orig_test = load_images_from_folder_original(original_root_path, exp2labels)\n",
        "\n",
        "images_test.update(images_orig_test)\n",
        "images_test.update(images_tamp_test)\n",
        "\n",
        "print(len(images_test['tampered']))\n",
        "print(len(images_test['original']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHE0qFymTPKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sifts = sift_features(images_train)\n",
        "\n",
        "# Takes the descriptor list which is unordered one\n",
        "descriptor_list = sifts[0] \n",
        "# Takes the sift features that is seperated class by class for train data\n",
        "all_bovw_feature = sifts[1] \n",
        "# Takes the sift features that is seperated class by class for test data\n",
        "test_bovw_feature = sift_features(images_test)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5CVqyWnbRrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Drawing keypoints to match similar features in original and tampered images:\")\n",
        "draw(images_train['original'][0], images_train['tampered'][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENLS33yBZCmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"SIFT descriptors are vectors of shape.\")\n",
        "print(\"Numerical representatin of SIFTs: \")\n",
        "print(sifts)\n",
        "print(\"Graphical representation of SIFTs:\")\n",
        "plt.imshow(np.array(sifts)[0][0].reshape(16,8), interpolation='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2r_DvVLgypT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Takes the central points which is visual words    \n",
        "visual_words = kmeans(2, descriptor_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbGO28_PTwLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates histograms for train data    \n",
        "bovw_train = image_class(all_bovw_feature, visual_words) \n",
        "# Creates histograms for test data\n",
        "bovw_test = image_class(test_bovw_feature, visual_words) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AbC_0GsT5bT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call the knn function    \n",
        "results_bowl = knn(bovw_train, bovw_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KAF737_UA_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculates the accuracies and write the results to the console.       \n",
        "accuracy(results_bowl)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}